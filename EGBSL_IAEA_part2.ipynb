{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4DX4HdNOzDmDcmpcIxX8Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbedart/EGBSL_IAEA/blob/main/EGBSL_IAEA_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<center><h1>EGBSL - IAES - Part #2</h1></center>**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "3zdYyw7DUHFu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dXm-K17lJgU6"
      },
      "outputs": [],
      "source": [
        "# @title Loading of prerequisites packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns; sns.set()\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn import preprocessing\n",
        "from sklearn import decomposition\n",
        "from sklearn import datasets\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import Image, display, clear_output, Javascript\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn.tree import export_graphviz, DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import seaborn as sns; sns.set()\n",
        "import plotly.express as px\n",
        "import pydotplus\n",
        "\n",
        "################################################################################\n",
        "\n",
        "launch_rf_hyperparameters = 0\n",
        "\n",
        "################################################################################\n",
        "\n",
        "def tree_graph_to_png(tree, feature_names, class_names, png_file_to_save):\n",
        "    tree_str = export_graphviz(tree, feature_names=feature_names, class_names=class_names,\n",
        "                                     filled=True, out_file=None)\n",
        "    graph = pydotplus.graph_from_dot_data(tree_str)\n",
        "    graph.write_png(png_file_to_save)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "np.seterr(divide='ignore', invalid='ignore')\n",
        "\n",
        "!wget https://github.com/cbedart/EGBSL_IAEA/raw/refs/heads/main/computed_desc_GR_tosave.pkl\n",
        "!wget https://github.com/cbedart/EGBSL_IAEA/raw/refs/heads/main/desc_GR_clustered_normalized_noNA.pkl\n",
        "!wget https://github.com/cbedart/EGBSL_IAEA/raw/refs/heads/main/desc_GR_PCA_53c.pkl\n",
        "\n",
        "computed_desc_GR_tosave = pd.read_pickle(\"computed_desc_GR_tosave.pkl\")\n",
        "desc_GR_clustered_prep = pd.read_pickle(\"desc_GR_clustered_normalized_noNA.pkl\")\n",
        "desc_GR_PCA_53c = pd.read_pickle(\"desc_GR_PCA_53c.pkl\")\n",
        "\n",
        "print(\"\\n\\n\\033[1mPrerequisites succesfully installed !\\033[0m\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <u>**Model \\#1 - Multiple linear regression (quantitative)**</u>"
      ],
      "metadata": {
        "id": "ZIjiRz0IVXEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Multiple linear regression model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "X = desc_GR_clustered_prep.iloc[:,4:]\n",
        "y = desc_GR_clustered_prep.loc[:,\"pIC50\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "model = LinearRegression(positive=True).fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "\n",
        "# Calculate mean squared error (for regression)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error (MSE) of Linear Regression: {mse:.2f}\")\n",
        "\n",
        "print(f\"Root Mean Squared Error (RMSE) of Linear Regression: {rmse:.2f}\")\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R-squared (R2) of Linear Regression: {r2:.2f}\\n\\n\")\n",
        "\n",
        "for i in range(len(y_pred)):\n",
        "  if abs(y_pred[i]) > 15:\n",
        "    print(X_test.index[i])\n",
        "    # print(y_pred + \"\\n\")\n",
        "\n",
        "plt.scatter(y_test, y_pred, s=10, zorder=22)\n",
        "plt.axline((0, 0), slope=1, linestyle=\"dashed\", c=\"black\")\n",
        "plt.xlim([4,11])\n",
        "plt.ylim([4,11])\n",
        "plt.xlabel(\"pIC50 theoretical\")\n",
        "plt.ylabel(\"pIC50 predicted\")\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rutSyLjZUpAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Feature importance of the multiple linear regression model\n",
        "\n",
        "coefs = pd.DataFrame(\n",
        "    model.coef_, columns=[\"Coefficients\"], index=X_train.columns\n",
        ")\n",
        "coefs = coefs.sort_values(\"Coefficients\")\n",
        "coefs.plot(kind=\"barh\", figsize=(5, 35))\n",
        "plt.title(\"Multiple linear regression model - Feature importance\")\n",
        "plt.axvline(x=0, color=\".5\")\n",
        "plt.subplots_adjust(left=0.3)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oCIKTxGjVZrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Second multiple linear regression model if we remove the coefficients < 1\n",
        "\n",
        "Xprep = desc_GR_clustered_prep.iloc[:,4:]\n",
        "X = Xprep.loc[:,coefs[\"Coefficients\"] > 1]\n",
        "y = desc_GR_clustered_prep.loc[:,\"pIC50\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "print(\"Only {} descriptors left\\n\".format(len(X.columns)))\n",
        "\n",
        "model2 = LinearRegression(positive=True).fit(X_train, y_train)\n",
        "y_pred2 = model2.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred2))\n",
        "\n",
        "# Calculate mean squared error (for regression)\n",
        "mse = mean_squared_error(y_test, y_pred2)\n",
        "print(f\"Mean Squared Error (MSE) of Linear Regression: {mse:.2f}\")\n",
        "\n",
        "print(f\"Root Mean Squared Error (RMSE) of Linear Regression: {rmse:.2f}\")\n",
        "\n",
        "r2 = r2_score(y_test, y_pred2)\n",
        "print(f\"R-squared (R2) of Linear Regression: {r2:.2f}\\n\\n\")\n",
        "\n",
        "for i in range(len(y_pred2)):\n",
        "  if abs(y_pred2[i]) > 15:\n",
        "    print(X_test.index[i])\n",
        "    # print(y_pred2 + \"\\n\")\n",
        "\n",
        "plt.scatter(y_test, y_pred2, s=10, zorder=22)\n",
        "plt.axline((0, 0), slope=1, linestyle=\"dashed\", c=\"black\")\n",
        "plt.xlim([4,11])\n",
        "plt.ylim([4,11])\n",
        "plt.xlabel(\"pIC50 theoretical\")\n",
        "plt.ylabel(\"pIC50 predicted\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "raA2RCb9VbKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <u>**Model \\#2 - Linear Discriminant Analysis (LDA) (qualitative)**</u>"
      ],
      "metadata": {
        "id": "HurGOI6bV8Ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Â @title Separation of the dataset into 3 classes: Active/Less active/Inactive\n",
        "\n",
        "active_picker = widgets.Dropdown(options=range(4,10), value=8, description=\"pIC50 limit of actives:\", style=dict(description_width='initial'))\n",
        "inactive_picker = widgets.Dropdown(options=range(4,10), value=6, description=\"pIC50 limit of inactives:\", style=dict(description_width='initial'))\n",
        "\n",
        "outs_active = widgets.Output()\n",
        "\n",
        "def generation_active(x):\n",
        "  with outs_active:\n",
        "    clear_output()\n",
        "\n",
        "    y = []\n",
        "    y_color = []\n",
        "    for i in desc_GR_clustered_prep.iloc[:,2]:\n",
        "      if i > active_picker.value:\n",
        "        y.append(\"Active\")\n",
        "        y_color.append(\"green\")\n",
        "      elif i < inactive_picker.value:\n",
        "        y.append(\"Inactive\")\n",
        "        y_color.append(\"orange\")\n",
        "      else:\n",
        "        y.append(\"LessActive\")\n",
        "        y_color.append(\"red\")\n",
        "\n",
        "    desc_GR_activity = pd.concat([desc_GR_clustered_prep.iloc[:,:4], pd.DataFrame(y, columns=[\"Activity\"]), desc_GR_clustered_prep.iloc[:,4:]], axis = \"columns\")\n",
        "\n",
        "    print(desc_GR_activity[\"Activity\"].value_counts())\n",
        "\n",
        "display(active_picker)\n",
        "display(inactive_picker)\n",
        "display(outs_active)\n",
        "\n",
        "generation_active(active_picker.value)\n",
        "active_picker.observe(generation_active, names='value')\n",
        "inactive_picker.observe(generation_active, names='value')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ywViTWY7V5nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Linear Discriminant Analysis with 3 classes\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset (or replace this with your dataset)\n",
        "y = [1 if i > active_picker.value else 0 for i in desc_GR_clustered_prep.iloc[:,2]]\n",
        "desc_GR_activity = pd.concat([desc_GR_clustered_prep.iloc[:,:4], pd.DataFrame(y, columns=[\"Activity\"]), desc_GR_clustered_prep.iloc[:,4:]], axis = \"columns\")\n",
        "\n",
        "ygroup = []\n",
        "ycat = []\n",
        "for i in desc_GR_clustered_prep.iloc[:,2]:\n",
        "  if i > active_picker.value:\n",
        "    ygroup.append(\"Active\")\n",
        "    ycat.append(1)\n",
        "  elif i < inactive_picker.value:\n",
        "    ygroup.append(\"Inactive\")\n",
        "    ycat.append(-1)\n",
        "  else:\n",
        "    ygroup.append(\"LessActive\")\n",
        "    ycat.append(0)\n",
        "\n",
        "desc_GR_activity = pd.concat([desc_GR_clustered_prep.iloc[:,:4], pd.DataFrame(ygroup, columns=[\"Activity_Label\"]), pd.DataFrame(ycat, columns=[\"Activity\"]), desc_GR_clustered_prep.iloc[:,4:]], axis = \"columns\")\n",
        "\n",
        "X = desc_GR_activity.iloc[:,6:]\n",
        "y = desc_GR_activity.loc[:,\"Activity\"]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an LDA instance\n",
        "lda = LinearDiscriminantAnalysis(store_covariance=True)\n",
        "\n",
        "# Fit LDA on the training data\n",
        "lda.fit(X_train, y_train)\n",
        "\n",
        "# Predict the classes on the test set\n",
        "y_pred = lda.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(\"Upper pIC50 value = {}\".format(active_picker.value))\n",
        "print(\"Lower pIC50 value = {}\".format(inactive_picker.value))\n",
        "\n",
        "print(f\"Accuracy of Linear Discriminant Analysis: {accuracy:.2f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "h395L9eAWBVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Feature importance of the 3 classes Linear Discriminant Analysis\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(10, 35))\n",
        "fig.subplots_adjust(left=2, right=3, top=1, bottom=0, wspace=2)\n",
        "# fig.tight_layout()\n",
        "\n",
        "coefs1 = pd.DataFrame(lda.coef_[0], columns=[\"Coefficients\"], index=X_train.columns)\n",
        "coefs1 = coefs1.sort_values(\"Coefficients\")\n",
        "\n",
        "coefs2 = pd.DataFrame(lda.coef_[1], columns=[\"Coefficients\"], index=X_train.columns)\n",
        "coefs2 = coefs2.sort_values(\"Coefficients\")\n",
        "\n",
        "coefs3 = pd.DataFrame(lda.coef_[2], columns=[\"Coefficients\"], index=X_train.columns)\n",
        "coefs3 = coefs3.sort_values(\"Coefficients\")\n",
        "\n",
        "# coefs1 = coefs1.sort_values(\"Coefficients\")\n",
        "# coefs1.plot(kind=\"barh\", figsize=(5, 15), ax=axes[1])\n",
        "# plt.title(\"Linear Discriminant Analysis model - Feature importance\")\n",
        "# plt.axvline(x=0, color=\".5\")\n",
        "# coefs2.plot(kind=\"barh\", figsize=(5, 15), ax=axes[0])\n",
        "\n",
        "\n",
        "axes[0].barh(np.arange(len(coefs1)), width=coefs1[\"Coefficients\"]);\n",
        "axes[0].set_title(\"Linear Discriminant Analysis model - Actives vs Others\", fontdict={'fontsize':10});\n",
        "axes[0].axvline(x=0, color=\".5\");\n",
        "axes[0].yaxis.set_ticks(np.arange(len(coefs1)));\n",
        "axes[0].yaxis.set_ticklabels(coefs1.index);\n",
        "\n",
        "axes[1].barh(np.arange(len(coefs2)), width=coefs2[\"Coefficients\"]);\n",
        "axes[1].set_title(\"Linear Discriminant Analysis model - Inactives vs Others\", fontdict={'fontsize':10});\n",
        "axes[1].axvline(x=0, color=\".5\");\n",
        "axes[1].yaxis.set_ticks(np.arange(len(coefs2)));\n",
        "axes[1].yaxis.set_ticklabels(coefs2.index);\n",
        "\n",
        "axes[2].barh(np.arange(len(coefs3)), width=coefs3[\"Coefficients\"]);\n",
        "axes[2].set_title(\"Linear Discriminant Analysis model - LessActives vs Others\", fontdict={'fontsize':10});\n",
        "axes[2].axvline(x=0, color=\".5\");\n",
        "axes[2].yaxis.set_ticks(np.arange(len(coefs3)));\n",
        "axes[2].yaxis.set_ticklabels(coefs3.index);"
      ],
      "metadata": {
        "cellView": "form",
        "id": "skGQNL49WicA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Linear Discriminant Analysis with 2 classes, 21 pIC50 limits, and Cross-Validation\n",
        "\n",
        "print(\"\\033[1mLDA models are currently being generated. It will take ~1 min\\033[0m\")\n",
        "\n",
        "accuracies_mean = []\n",
        "accuracies_sd = []\n",
        "accuracies_split = []\n",
        "accuracies_nbActives = []\n",
        "accuracies_nbInactives = []\n",
        "\n",
        "for pic50_limit in [j/100 for j in range(500,1001,25)]:\n",
        "  ygroup2 = []\n",
        "  ycat2 = []\n",
        "  for i in desc_GR_clustered_prep.iloc[:,2]:\n",
        "    if i > pic50_limit:\n",
        "      ygroup2.append(\"Active\")\n",
        "      ycat2.append(1)\n",
        "    else:\n",
        "      ygroup2.append(\"Inactive\")\n",
        "      ycat2.append(0)\n",
        "\n",
        "  desc_GR_activity2 = pd.concat([desc_GR_clustered_prep.iloc[:,:4], pd.DataFrame(ygroup2, columns=[\"Activity_Label\"]), pd.DataFrame(ycat2, columns=[\"Activity\"]), desc_GR_clustered_prep.iloc[:,4:]], axis = \"columns\")\n",
        "\n",
        "  accuracies_nbInactives.append(desc_GR_activity2[\"Activity_Label\"].value_counts()[\"Inactive\"])\n",
        "  accuracies_nbActives.append(desc_GR_activity2[\"Activity_Label\"].value_counts()[\"Active\"])\n",
        "\n",
        "  X2 = desc_GR_activity2.iloc[:,6:]\n",
        "  y2 = desc_GR_activity2.loc[:,\"Activity\"]\n",
        "\n",
        "  X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
        "  lda2 = LinearDiscriminantAnalysis(store_covariance=True)\n",
        "  lda2.fit(X_train2, y_train2)\n",
        "\n",
        "  from sklearn.model_selection import cross_val_score\n",
        "  from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "  y_pred2 = lda2.predict(X_test2)\n",
        "\n",
        "  cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
        "  scores = cross_val_score(lda2, X2, y2, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "\n",
        "  accuracy2 = accuracy_score(y_test2, y_pred2)\n",
        "\n",
        "  accuracies_mean.append(round(np.mean(scores), 2))\n",
        "  accuracies_sd.append(round(np.std(scores), 2))\n",
        "  accuracies_split.append(pic50_limit)\n",
        "\n",
        "\n",
        "plt.scatter(accuracies_split, accuracies_mean)\n",
        "plt.plot(accuracies_split, accuracies_mean)\n",
        "plt.fill_between(accuracies_split, [i-j for i,j in zip(accuracies_mean,accuracies_sd)], [i+j for i,j in zip(accuracies_mean,accuracies_sd)], color=\"#0000FF11\")\n",
        "plt.xlabel(\"Limit of pIC50 between the 2 groups\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim([0.7,1.05])\n",
        "plt.show()\n",
        "\n",
        "pd.DataFrame([accuracies_mean, accuracies_sd, accuracies_nbActives, accuracies_nbInactives], index=[\"Accuracy mean\", \"Accuracy std\", \"Total actives\", \"Total inactives\"], columns=accuracies_split)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "L89qiT-1Wk72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <u>**Model \\#3 - Decision tree**</u>"
      ],
      "metadata": {
        "id": "CeuZP8akXJHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Prepare the data for decision tree and random forest models\n",
        "\n",
        "desc_GR_DTs = desc_GR_clustered_prep\n",
        "\n",
        "pic50_limit = 8\n",
        "\n",
        "ygroup2 = []\n",
        "ycat2 = []\n",
        "for i in desc_GR_DTs.iloc[:,2]:\n",
        "  if i > pic50_limit:\n",
        "    ygroup2.append(\"Active\")\n",
        "    ycat2.append(1)\n",
        "  else:\n",
        "    ygroup2.append(\"Less Active\")\n",
        "    ycat2.append(0)\n",
        "\n",
        "desc_GR_activity2 = pd.concat([desc_GR_DTs.iloc[:,:4], pd.DataFrame(ygroup2, columns=[\"Activity_Label\"]), pd.DataFrame(ycat2, columns=[\"Activity\"]), desc_GR_DTs.iloc[:,4:]], axis = \"columns\")\n",
        "\n",
        "X2 = desc_GR_activity2.iloc[:,6:]\n",
        "y2 = desc_GR_activity2.loc[:,\"Activity\"]\n",
        "\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
        "\n",
        "################################################################################\n",
        "\n",
        "print(\"\\nWe setup the pIC50 limit to {}, with :\".format(pic50_limit))\n",
        "print(\"- A total of {} active compounds (pIC50 < {}) - Coded as 1\".format(desc_GR_activity2[\"Activity\"].value_counts()[1], pic50_limit))\n",
        "print(\"- A total of {} less active compounds (pIC50 > {}) - Coded as 0\".format(desc_GR_activity2[\"Activity\"].value_counts()[0], pic50_limit))\n",
        "\n",
        "print(\"\\n\\033[1mDone !\\033[0m \\n\\n\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "C2-5O9UsCTvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title First decision tree\n",
        "\n",
        "dt1 = DecisionTreeClassifier()\n",
        "dt1.fit(X_train2, y_train2)\n",
        "\n",
        "y_pred_dt1 = dt1.predict(X_test2)\n",
        "# dt1_confusion = pd.DataFrame(confusion_matrix(y_test2, y_pred_dt1), columns=[\"Less Actives\", \"Actives\"], index=[\"Less Actives\", \"Actives\"])\n",
        "\n",
        "print(\"Accuracy on the train set = {}\\n\".format(round(dt1.score(X_train2, y_train2),3)))\n",
        "print(\"Accuracy on the test set = {}\".format(round(dt1.score(X_test2, y_test2),3)))\n",
        "\n",
        "cvk_dt1 = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
        "scores_cvk_dt1 = cross_val_score(dt1, X2, y2, scoring='accuracy', cv=cvk_dt1, n_jobs=-1)\n",
        "\n",
        "print(\"Accuracy using 10-fold Cross Validation = {}\\n\".format(round(np.mean(scores_cvk_dt1),3)))\n",
        "\n",
        "\n",
        "tree_graph_to_png(dt1, feature_names=X2.columns, class_names=[\"Less Actives\", \"Actives\"], png_file_to_save='dt1.png')\n",
        "\n",
        "print(\"Confusion matrix:\")\n",
        "fig, axn = plt.subplots(1,2, figsize=(12,3))\n",
        "axn[0].grid(False) ; axn[1].grid(False)\n",
        "confusion1_dt1 = ConfusionMatrixDisplay.from_estimator(dt1, X_test2, y_test2, display_labels=[\"Less Active\", \"Active\"], ax=axn[0], cmap=plt.cm.Blues, normalize=None)\n",
        "confusion1_dt1.ax_.set_title(\"Confusion matrix, without normalization\")\n",
        "# confusion1_dt1\n",
        "confusion2_dt1 = ConfusionMatrixDisplay.from_estimator(dt1, X_test2, y_test2, display_labels=[\"Less Active\", \"Active\"], ax=axn[1], cmap=plt.cm.Blues, normalize=\"true\")\n",
        "confusion2_dt1.ax_.set_title(\"Normalized confusion matrix\")\n",
        "# confusion2_dt1\n",
        "plt.show()\n",
        "\n",
        "dt1_acc_pr_rec = [round(dt1.score(X_train2, y_train2),3),\n",
        "                  round(dt1.score(X_test2, y_test2),3),\n",
        "                  round(confusion2_dt1.confusion_matrix[1,1] / (confusion2_dt1.confusion_matrix[1,1] + confusion2_dt1.confusion_matrix[0,1]), 3),\n",
        "                  round(confusion2_dt1.confusion_matrix[1,1] / (confusion2_dt1.confusion_matrix[1,1] + confusion2_dt1.confusion_matrix[1,0]), 3)]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SwzQYfYjXKqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Display the first decision tree\n",
        "\n",
        "# @markdown Do not hesitate to right clic >>> \"Open in a new tab\" to better see the tree\n",
        "\n",
        "display(Image('dt1.png'))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DIxFSkaQXf6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <u>**Model \\#4 - Random forest**</u>"
      ],
      "metadata": {
        "id": "qELGkM58Bsjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Build the first random forest model\n",
        "\n",
        "# @markdown Choose the number of decision trees you will generate:\n",
        "number_of_trees = 100 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown Choose if you set an early termination of the trees after X splits, or just build the bigger trees you can (= None)\n",
        "maximum_depth = \"3\" # @param [\"None\", 1, 2, 3, 4, 5]\n",
        "\n",
        "if maximum_depth == \"None\":\n",
        "  maximum_depth = None\n",
        "else:\n",
        "  maximum_depth = int(maximum_depth)\n",
        "\n",
        "print(\"\\n\\033[1mUsing {} decision trees with an early termination setup at {}\\033[0m\\n\".format(number_of_trees, maximum_depth))\n",
        "\n",
        "rf1 = RandomForestClassifier(n_estimators = number_of_trees, max_depth = maximum_depth, random_state=42)\n",
        "rf1.fit(X_train2, y_train2)\n",
        "\n",
        "y_pred_rf1 = rf1.predict(X_test2)\n",
        "rf1_confusion = pd.DataFrame(confusion_matrix(y_test2, y_pred_rf1), columns=[\"Less Actives\", \"Actives\"], index=[\"Less Actives\", \"Actives\"])\n",
        "\n",
        "print(\"Accuracy on the train set = {}\\n\".format(round(rf1.score(X_train2, y_train2),3)))\n",
        "print(\"Accuracy on the test set = {}\".format(round(rf1.score(X_test2, y_test2),3)))\n",
        "\n",
        "cvk_rf1 = RepeatedStratifiedKFold(n_splits=5, n_repeats = 3, random_state=1)\n",
        "scores_cvk_rf1 = cross_val_score(rf1, X2, y2, scoring='accuracy', cv=cvk_rf1, n_jobs=-1)\n",
        "\n",
        "print(\"Accuracy using 5-fold Cross Validation = {}\\n\".format(round(np.mean(scores_cvk_rf1),3)))\n",
        "\n",
        "print(\"Confusion matrix:\")\n",
        "fig, axn = plt.subplots(1,2, figsize=(12,3))\n",
        "axn[0].grid(False) ; axn[1].grid(False)\n",
        "confusion1_rf1 = ConfusionMatrixDisplay.from_estimator(rf1, X_test2, y_test2, display_labels=[\"Less Active\", \"Active\"], ax=axn[0], cmap=plt.cm.Blues, normalize=None)\n",
        "confusion1_rf1.ax_.set_title(\"Confusion matrix, without normalization\")\n",
        "# confusion1_rf1\n",
        "confusion2_rf1 = ConfusionMatrixDisplay.from_estimator(rf1, X_test2, y_test2, display_labels=[\"Less Active\", \"Active\"], ax=axn[1], cmap=plt.cm.Blues, normalize=\"true\")\n",
        "confusion2_rf1.ax_.set_title(\"Normalized confusion matrix\")\n",
        "# confusion2_rf1\n",
        "plt.show()\n",
        "\n",
        "rf1_acc_pr_rec = [round(rf1.score(X_train2, y_train2),3),\n",
        "                  round(rf1.score(X_test2, y_test2),3),\n",
        "                  round(confusion2_rf1.confusion_matrix[1,1] / (confusion2_rf1.confusion_matrix[1,1] + confusion2_rf1.confusion_matrix[0,1]), 3),\n",
        "                  round(confusion2_rf1.confusion_matrix[1,1] / (confusion2_rf1.confusion_matrix[1,1] + confusion2_rf1.confusion_matrix[1,0]), 3)]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0ELITEUMBqhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Hyperparameters optimization of the random forest model\n",
        "\n",
        "if launch_rf_hyperparameters == 1:\n",
        "  raise FileExistsError('Already done')\n",
        "\n",
        "rf_accuracies_train = []\n",
        "rf_accuracies_test = []\n",
        "rf_precision_test = []\n",
        "rf_recall_test = []\n",
        "\n",
        "\n",
        "for maximum_depth_loop in [1, 2, 3, 4, 5, None]:\n",
        "  for number_of_trees_loop in [10,100,1000]:\n",
        "  # for number_of_trees_loop in [10,100,1000,10000]:\n",
        "    print(\"Currently running depth {} with {} trees\".format(maximum_depth_loop, number_of_trees_loop))\n",
        "    rfloop = RandomForestClassifier(n_estimators = number_of_trees_loop, max_depth = maximum_depth_loop, random_state=42)\n",
        "    rfloop.fit(X_train2, y_train2)\n",
        "    y_pred_rfloop = rfloop.predict(X_test2)\n",
        "    rfloop_confusion = confusion_matrix(y_test2, y_pred_rfloop, normalize=None)\n",
        "\n",
        "    rf_accuracies_train.append(round(rfloop.score(X_train2, y_train2),3))\n",
        "    rf_accuracies_test.append(round(rfloop.score(X_test2, y_test2),3))\n",
        "    rf_precision_test.append(round(rfloop_confusion[1,1] / (rfloop_confusion[1,1] + rfloop_confusion[0,1]), 3))\n",
        "    rf_recall_test.append(round(rfloop_confusion[1,1] / (rfloop_confusion[1,1] + rfloop_confusion[1,0]), 3))\n",
        "\n",
        "\n",
        "print(\"\\n\\033[1mDone !\\033[0m\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DLg6EQFdBuS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Plot for the hyperparameters optimization\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(rf_accuracies_train, marker=\".\")\n",
        "plt.plot(rf_accuracies_test, marker=\".\")\n",
        "plt.plot(rf_precision_test, marker=\".\")\n",
        "plt.plot(rf_recall_test, marker=\".\")\n",
        "plt.title(\"Quality assessment metrics for RF hyperparameters optimization\")\n",
        "plt.legend([\"Accuracy train\", \"Accuracy test\", \"Precision\", \"Recall\"])\n",
        "plt.ylim([-0.05,1.05])\n",
        "\n",
        "labels = []\n",
        "for maximum_depth_loop in [1, 2, 3, 4, 5, None]:\n",
        "  # for number_of_trees_loop in [10,100,1000,10000]:\n",
        "  for number_of_trees_loop in [10,100,1000]:\n",
        "    labels.append(\"{} / {}\".format(maximum_depth_loop, number_of_trees_loop))\n",
        "\n",
        "plt.xticks(range(18), labels, rotation='vertical')\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fElHTfzIBvT3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}